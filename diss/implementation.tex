\chapter{Implementation}

In this chapter I describe the work that was undertaken while building this project. I start by explaining my initial prototyping strategy before giving an overview of the final project structure, how each part of it was implemented and why particular design choices were made. This includes the library itself, the command-line client that uses it and the daemon for synchronising a Gitmaildir with a Maildir. I then also covers how concurrency was managed, other topics relating to how the project was structured and finally I give a short description of the extensions that were completed and an overview of the repository layout.

\section{Bash prototype}

At first it was necessary to test whether the operations I wanted to perform were possible at all and whether they were possible to implement in the manner that I hoped. This was made easier by the existence of the git command-line tool. As described earlier, this tool is the standard interface to a Git store and also has a working implementation of all of the Git plumbing commands. As it is a tool intended to work in a shell environment I felt it was prudent to write bash scripts to implement each of the basic features. Bash was selected as it is the shell which I use on my personal machine and is widely supported.

The features implemented in this prototype were basic email delivery, renaming, and conversion of a Maildir to a git store. These all functioned as intended (albeit with a higher level of manual intervention than exists in the final codebase). Due to the success of the prototype, I knew that what I wanted to implement was possible in the way I intended to do it. Therefore it would be possible to translate into OCaml in a more structured way with the opportunity to implement more features.

\section{Gitmaildir}

\subsection{Structural overview} \label{section:structuraloverview}

The project is split into 3 logically distinct sections:
\begin{itemize}
  \item \texttt{Gitmaildir}, an OCaml library providing all of the functionality necessary to interact with a gitmaildir.
  \item \texttt{gitmaildir\_cli}, a command-line tool to interact with a gitmaildir. It is written in OCaml and uses the features of the \texttt{Gitmaildir} library. It is a demo tool to show what operations can be performed and to provide a correct implementation for them.
  \item \texttt{gitmaildir\_daemon}, another command-line application. It runs as a daemon, syncronising a standard Maildir with a Gitmaildir to allow applications which already know how to use a Maildir to use a Gitmaildir indirectly.
\end{itemize}

\subsection{Mapping between Maildir and Git store} \label{section:mapping}

As a Maildir is simply files stored in directories and Git is designed to store files in different versions, the mapping is mostly straightforward. A Gitmaildir follows exactly the same structure as a Maildir except that it does not have the \texttt{tmp} folder. The reason for this omission is that the \texttt{tmp} folder is used for concurrency protections when writing to the filesystem. However this is all managed by the Gitmaildir client in use which makes it unnecessary to ever write to it. It is therefore unnecessary to keep this folder. Also, it is important to note that Git cannot store empty directories, they must contain at least one file which was another reason for not maintaining the \texttt{tmp} directory. However, to get around this problem for necesssary directories I had to create a file called \texttt{.keep} to act as the only file in an empty directory.

Originally there were plans to move metadata such as the flags added to the end of file names into the first line of email files so that the filenames in the Git store did not change. The benefits of this strategy would have been that no semantically important data would be stored in git tree objects (as all that is stored there are file names which are unique identifiers and do not tell us important details about the data contained within). However, this adds complexity when adding to and reading from a Gitmaildir. It also would mean that changing a flag on an email changes the file hash, and so a new copy of the email is stored under the new hash. Git internally does use forms of diffing to compress the store contents so that this is not as much of an issue. However it does add complexity for no real gain which is why I decided that it was not a worthwhile feature.

Overall, even with the differences in how information is stored, it is designed in such a way that no information is lost, meaning that a conversion between the two is completely reversible.

An additional feature that Git provides on top of the standard filesystem is branching. This is not used in the basic representation of a Gitmaildir, however it is very useful for the extension features. Therefore it is reserved for these and will be described later in section \ref{section:extensions}

\subsection{The Gitmaildir Library}

As decided in the requirements analysis, the Gitmaildir library provides the following features:

\begin{itemize}
\item email delivery
\item email move/rename (this includes altering flags)
\item email deletion
\item conversion of a maildir to a gitmaldir (and vice versa)
\item the ability to add different hooks when a modification occurs so that extensions can be implemented more easily
\end{itemize}

All of these operations required interaction between the filesystem and/or interaction with a git store. To manage interaction with a git store I used the library ocaml-git. As all this provided was the means to read and write different types of elements of a Git store in a consistent way it was necessary to implement the functionality of some of the Git plumbing commands almost from scratch.

The library itself was separated into a few different sections depending on functionality. There is the \texttt{Git\_ops} module which implements all the necessary Git features on top of ocaml-git. This includes plumbing command features such as adding blobs to Git trees and other features such as initialising a Gitmaildir. To implement these I had to follow how Git builds commits to leave the store in a correct state. Algorithm \ref{algorithm:addtostore} shows the method used to add a new blob (ie file) to a Git store at a particular location in the tree.

\begin{algorithm}[h]
\SetAlgoLined
\DontPrintSemicolon

\KwData{$D=$ data to write to store, $P=$ path as a list}
\KwResult{Store is updated with head pointing to the new tree}

\SetKwFunction{FMain}{AddToTree}
\SetKwProg{Fn}{Function}{:}{}

\BlankLine
\tcc{First we write the data to the store}
$ dataHash \leftarrow \textrm{WriteBlob}(D) $\;

\BlankLine
\tcc{Then we define the function to update the tree}
\SetKwFunction{FMain}{AddToTree}
\SetKwProg{Fn}{Function}{:}{}
\Fn{\FMain{$H$, $L$, $T$}}{
  \eIf{$L = [\,]$}
  {$ tree \leftarrow \textrm{ReadTree}(T) $\;
   $ newTree \leftarrow \textrm{AddElementInTree}(tree, dataHash) $\;
   $ treeHash \leftarrow \textrm{WriteTree}(newTree) $\;
   $ \textbf{return } treeHash $}
  {$ \mathit{head, tail} \leftarrow L $\;
   $ tree \leftarrow \textrm{ReadTree}(T) $\;
   $ subtree \leftarrow \textrm{EntryFromTree}(tree, head) $\;
   \tcc{The recursive call is here}
   $ newSubtreeHash \leftarrow \textrm{AddToTree}(H, tail, subtree) $\;
   $ updatedTree \leftarrow \textrm{ReplaceInTree}(tree, head, newSubtreeHash) $\;
   $ treeHash \leftarrow \textrm{WriteTree}(updatedTree) $\;
   $ \textbf{return } treeHash $\;}
}
\textbf{end}

\BlankLine
\tcc{Now we update the tree and write the new commit}
$ newTreeHash \leftarrow \textrm{AddToTree}(dataHash, P, oldTree) $\;
$ newCommit \leftarrow \textrm{BuildCommit}(newTreeHash, oldCommit) $\;
$ \textrm{UpdateHeadReference}(newCommit) $\;
\caption{How to add data to a Git store}
\label{algorithm:addtostore}
\end{algorithm}
\medskip

In effect this is a standard tree traversal where we walk down to the directory we want to update and then walk back up from that point rewriting all the nodes and pointers along the way. In fact, most operations on the Git store involve traversing the tree to a point, making a change of some sort and then walking back up. This is quite useful for implementation as it means that the tree traversal only has to be written once. After writing this I was then able to add quite a few features such as rename, addition and deletion as different modifications. This was fairly straightforward because OCaml is a functional language. This means that it has first class functions so the necessary function can be passed as an argument to the method that implements the tree walking.

While writing these methods it became obvious that a lot of things were harder to read and more verbose than they could be. This was because almost all of the operations interact with the filesystem so they were therefore wrapped in an Lwt monad. Also, these operations can almost all cause errors so they were then wrapped in a Result monad. This made the types quite complicated and therefore difficult to work with in a way that was both clear and concise. To solve this I added a few helper functions in the form of extra infix operators. These were operators which allowed me to bind or map functions across both or either of the Result and Lwt parts of any value. An example of code written before using these infix operators can be seen in Listing \ref{listing:noinfix}.

\begin{listing}[h]
\begin{minted}{ocaml}
let init_empty_blob store =
  let blob = Store.Value.Blob.of_string "" |> Store.Value.blob in
  Result.map ~f:(Lwt.map (fun h ->
                            Tree.of_list [Tree.entry ".keep" `Normal h]))
                   write_value store blob
  |> Result.map ~f:(Lwt.map Store.Value.tree)
  |> Result.bind ~f:(Lwt.bind write_value store)
  |> Result.bind ~f:(Lwt.bind commit_tree store [] "init")
  |> Result.bind ~f:(Lwt.bind update_ref store Git.Reference.master)
\end{minted}
\caption{Code segment before the use of new infix operators}
\label{listing:noinfix}
\end{listing}

We can see in Listing \ref{listing:noinfix} that there is a lot of repetition in this code. The structures of each line are all almost identical and the nested ordering required means that the operation taking place is not immediately obvious. Therefore, I rewrote the same code using the new infix operators that I had defined. The definitions of these operators can be seen in Listing \ref{listing:infixdef}.

\begin{listing}[h]
\begin{minted}{ocaml}
let (>>||) x f = Lwt_result.map f x
let (>>=|) = Lwt_result.bind_result
let (>>==) = Lwt_result.bind
\end{minted}
\caption{Code segment of the definitions of the new infix operators}
\end{listing}

\begin{listing}[h]
\begin{minted}{ocaml}
let init_empty_blob store =
  let blob = Store.Value.Blob.of_string "" |> Store.Value.blob in
  write_value store blob
  >>|| (fun h -> Tree.of_list [Tree.entry ".keep" `Normal h])
  >>|| Store.Value.tree
  >>== write_value store
  >>== commit_tree store [] "init"
  >>== update_ref store Git.Reference.master
\end{minted}
\caption{Code segment with the use of new infix operators}
\label{listing:infix}
\end{listing}

We can see in Listing \ref{listing:infix} the nested application of two functions is now contained in one infix operator which also fits visually with the flow of the data through the code. Because of these two factors the code became quicker to write and it also felt more natural to read. Although this is just a small example, these patterns exist in almost every function in the codebase, meaning that it does have a large impact on efficiency when both reading and writing code throughout the project.

Once implementation of the necessary git operations was complete it was possible to move on to writing Maildir operations. These are all held in a separate module aptly named \texttt{Maildir}. Most of the functionality was created by wrapping sequences of functions from \texttt{Git\_ops} to provide standalone Maildir functions without having to worry about the Git backend. In fact this was one of the many uses of an OCaml functor in my project. When one wishes to use the Maildir module they must first pass in a module which provides the necessary Git operations. This implementation is then used by the \texttt{Maildir} module to interact with a Git store.

The implementation of most operations such as deleting an email was fairly straightforward as they just consist of reading information about the store, performing the modification and then writing back any results\footnote{One extra feature that did need adding to this flow was locking but this is described later in section \ref{section:concurrency}}. However, a few operations required some new thought. One such operation was email delivery as we have to assign a unique name to each new email. The format for this is specified by the original author\cite{bernstein2000maildir} as:
\begin{quote}
  Okay, so you're writing messages. A unique name has three pieces, separated by dots. On the left is the result of time() or the second counter from gettimeofday(). On the right is the result of gethostname(). (To deal with invalid host names, replace / with \textbackslash057 and : with \textbackslash072.) In the middle is a delivery identifier, discussed below.
\end{quote}
This works under most circumstances but it is still possible to end up with two identical names. Therefore we need a solution for collisions. As the original implementation of Maildir uses the filesystem the suggestion is to sleep 2 seconds and try again. Because of using Git the name collision check takes longer and so will take also longer to throw an error. My current implementation throws an error if the name is taken and the process has to try again. I think this is similar behaviour to the original, as in this case the delivering process cannot check for itself if the name collides. However, due to the locking in use (described in more detail in section \ref{section:concurrency}), it would be possible to safely generate the name at the point of adding it to the git tree whilst also not having to worry about collisions. This would be the best solution in terms of speed, but it would violate the layers of abstraction in my modules which is why I chose not to implement it.

The reason that this would violate layers of abstraction is that I have a module that manages Git operations and one that manages Maildir operations using those Git operations. In this instance we would be performing a Maildir operation (generating a name for a new email) inside a Git operation (while writing said email to the store). This would mean that rather than sitting atop the Git module, Maildir functionality would have to be built into it. This could be avoided by allowing the passing of a name-picking function to the Git\_ops module, however this is still supporting a very specific problem which is only really relevant to Maildir and the end result of performing Maildir operations inside Git operations still exists.

\subsection{Command line interface}

I decided as part of my requirements that is would be useful to have a way to interact with a Gitmaildir through the command-line, providing a way to execute all of the operations implemented. This was not only for human interaction, but also as a tool that other programs could call if not able to use the Gitmaildir library directly. I built this with the help of an OCaml library called cmdliner which ``allows the declarative definition of command line interfaces for OCaml''\cite{code_cmdliner}. This allowed me to design and create the interface without having to worry about parsing arguments into the correct type or even to think about whether all the arguments had been provided and any other errors.

The library is used by creating a `term' which is evaluated and terms can be built from sub-terms. The library provides a way to create terms from arguments and a way to create terms from OCaml functions. These terms can then be coupled together to form the complete program term which cmdliner evaluates as your program. The declarative and compositional manner in which this is done was new to me and was at first confusing but after understanding how it worked it made adding and changing arguments in the command-line very fast and simple. It had the further benefit that for similar arguments you can parametrise a function that builds a different term based on the argument given which saves time and code. However this strategy was less readable so I did not use it in the end and created each term separately.

\subsection{Daemon}

The purpose of the daemon, as described above, is to synchronise a normal Maildir with a Gitmaildir. This is to allow programs which only work with a Maildir to use a Gitmaildir as a backend indirectly. As with all of the other code this was implemented in OCaml. Like the command-line interface, the interface for the daemon was also created using cmdliner.

There were many different ways in which I could have implemented the daemon, the main three being continually polling the filesystem (which would have been inefficient), being notified by Gitmaildir clients (but this does not help for clients which only know about Maildir) and subscribing to filesystem changes in a more a less resource-intensive way. I opted for option 3 by using a file change monitor called fswatch\cite{code_fswatch}. The benefit of using this tool in particular is that it handles interoperability with most major OSs (macOS, Linux, BSD, Windows), and on all of those OSs it uses notifications from the OS for file changes rather than polling the filesystem. This allowed me to focus on programming the syncing process itself rather than worrying about how to be notified of changes on different systems.

Once we have knowledge of a change having happened we have to work out what needs to be done. I did this by calculating a diff (of the files as contents of a directory as opposed to the contents of the files themselves) between the files in Git storage and those in Maildir storage on every notification.

The diff itself was calculated by a reading in a list of the contents of each directory and checking to see if each item was a member of the other. I was able to use this as opposed to a more standard method such as computing the longest common subsequence because ordering does not matter and all the filenames are unique. Once the diff has been performed I then check for emails which have the same name but only the flags are changed as this indicates a modification as opposed to a new delivery or deletion. In the next paragraph I will describe how the information outputted from this process is used.

Additions of new emails are easy to handle as we just need to make a new write. Moves are also easy to track as the only name changes come from editing the flags at the end of a file name, the rest of it always remains the same. The more difficult operation comes from deletion as na\"{\i}vely it looks the same as an addition to the alternate store. I solved this by using the Git history: If we look at the previous commit it should be the one before the deletion took place. If the email existed in the previous Git commit then a deletion took place (it is the same for the Maildir and Gitmaildir) so we can safely delete it from the relevant store. In this way we can see that although Git does come with an associated cost it does have benefits from the history that it brings.

\subsection{Concurrency protections} \label{section:concurrency}

Maildir was designed in such a way that people implementing it do not need to worry about locking as long as they follow the correct procedure when writing to a Maildir (as it is all handled by the filesystem). This was one of the main points behind its design but, as explained earlier, this is also why it is not strongly consistent. Implementing a Maildir in Git has meant that all writes to it have to be as part of a Git commit. This unfortunately means that locking is required. The reason for this stems from the structure of a Git repository on disk and can best be explained by an example of when things go wrong. Here is an example of what could happen if two processes try to deliver an email concurrently (using the process described in algorithm \ref{algorithm:addtostore}):

\begin{enumerate}[topsep=1pt,itemsep=-1ex,partopsep=1ex,parsep=1ex]
\item Processes 1 and 2 start their delivery of emails A and B
\item A and B are both written to the store returning hashes
\item Process 1 is returned a modified tree containing A
\item Process 2 is returned a modified tree containing B
\item Process 1 commits its new tree and moves forward the HEAD
\item Process 2 commits its new tree and moves forward the HEAD
\end{enumerate}

At the end of this sequence of actions we have the HEAD reference pointing to a commit which contains email B but not email A. The previous commit in the history will contain email A and not email B. However, the expected result would be for the HEAD commit to contain A and B and the previous one to contain only one of them (depending on order of delivery). The only way to achieve this is some form of concurrency control. I decided that the simplest solution would be to use locking.

I implemented the locking using a combination of the BSD tool/system call flock\cite{manual_flock} and the Mutex module from the OCaml standard library. Flock was necessary for interprocess locks as multiple processes could be trying to write at the same time and should not be allowed to. Flock is fiarly simple, it creates a lock associated with a particular file (I created a file to act as the lock file for any process called \texttt{.global\_lock}) in the filesystem. This can be shared, exclusive or non-blocking. I decided on exclusive for all cases. It would be possible to use a shared lock for reading but this would have added further complexity. The reason that it was also necessary to use Mutex was that Flock prevents different processes from holding a lock at the same time but is effectively reentrant for the same process. Therefore if we need concurrency protections and are executing inside the same process then something else to provide the locking. The reason that Mutex could not be used for all the locking is the opposite from Flock: it only works inside a single process.

When adding the locking strategy, I initially put a lock around every Maildir operation. This did work and provided safety, however, more granular locking was possible. The only place where a write could collide is in updating the which commit is the HEAD of the repository. Therefore this is the only operation that we need a lock around. However, unlike the whole-operation locking this does not solve the race-condition described above. The way that this can be resolved is by checking if we have had a race inside the lock. If we have not then it is okay to continue. If we have then our tree is missing at least one change so we have to roll back and try again. Due to the possible need to roll back, this could end up being slower than the purely sequential method. However, I noticed something else about the flow of adding to a store: adding the blob and getting a hash back is an idempotent operation due to the content-addressable storage. This is one of the longer running parts of the process but will never be part of the race so we also only have to every perform it once. Therefore I was able to remove this stage from the roll back. Comparisons of the different strategies can be seen in section \ref{section:evaluation} of this document.

\subsection{Build system}

For the project I chose to use the Dune\cite{code_dune} build system. This was because it is the most widely used build system for OCaml currently, has a lot of documentation, has all the features I needed and is quick (it supports concurrent builds). The main benefits to using it were that I was able to create build files for each part of the project separately, mentioning their different dependencies and what they were (eg command-line interface or library) and a single file in the root directory to specify it was one project. Given those files Dune can build, install and test the entire project. Alongside this it does support some other useful features, one of which is generating HTML documentation from the docstrings in the code. An example of the generated documentation for the Git\_ops module is provided in the appendix, section \ref{section:docs}.

\subsection{Unit tests}

TODO

Parts:
- Choice of library (alcotest) (discuss inline AST rewrite tests)
- How tests were written
- How results were used/benefitted process

The first thing that had to be done about unit testing was choosing a library. In OCaml there is a lot of choice for libraries to use and there does not seem to be one standard that most people use so I had to thoroughly assess the different options. It turned out that were two main types of unit testing possible:
Inline tests...

\section{Extensions} \label{section:extensions}

I came up with ideas for multiple possible extensions in the form of plugins providing new features. I chose to implement one of these along with the plugin system to make it possible as my extensions.

The plugin system works by using OCaml's functors along with the ability to package modules as values. I first created a new module called \texttt{Maildir\_with\_plugins} to hold the code for the plugin system. The design of the system is that any time a Maildir operation is called, you can provide your own function which will be executed with the same arguments immediately after it (this is guaranteed by both operations being inside the same lock). This is implemented by a functor which takes as input a module implementing a Gitmaildir and a module implementing the plugin functions (it must have a specific signature). This then returns a module implementing a Gitmaildir augmented with the plugin. The interesting thing to note here is that this augmented module can then have another plugin added to it in exactly the same manner, effectively allowing us to wrap as many plugins around a Gitmaildir implementation as we want to. This wrapping can be automated as it is possible to pack modules as values and unpack them later in OCaml. This meant that I was able to create another function which takes a base Gitmaildir implementation and a list of plugin implementations, applys them all and then returns the augmented module. This could, given more time, be extended further using an OCaml feature called `Dynlink' which allows the loading of new modules at a point after compilation. This would make it possible to bundle plugins separately to the main library making it easier to add new ones and change the runtime configuration without recompilation.

Using this system I wrote a plugin that for every operation performs the same operation but on a different branch where all the emails are plain text. A possible use case for this would be for clients on a low bandwidth internet connection so they do not want to have to download big attachments and images. All of the operations except for delivery are quite simple as they are exactly the same as for the standard branch. For the delivery case, I had to create a way to transform all incoming emails to plain text. To perform this I used and OCaml library called `email\_message' which aids in parsing emails. Using it I was able to recursively parse the MIME email format to discard attachments that were not plain text, concatenate parts that were into a single message, and pick the plain text option when multiple alternative message bodies were sent as part of the same email. In the case when a plain text alternative was not present I had to convert HTML to plain text. Whilst it would have been possible to do this in OCaml I felt it was beyond the scope of this project, so instead the plugin uses an external python tool called `html2text' which it sends the HTML to and receives plain text back from.

\section{Repository overview}

The code repository is laid out in a fairly self-descriptive way. The top level directory contains build files; the license; a readme giving instructions on how to build the application, and use the tools and library; and the all the code separated into subdirectories with the same structure as specified in \ref{section:structuraloverview}. There is also a directory of tests which are the unit tests used in the evaluation. Finally there is a folder named evaluation containing the scripts used to perform the performance tests, the coded to provide the timing, and the code implementing the Maildir and Mbox functionality to compare against.
