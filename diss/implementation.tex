\chapter{Implementation}

In this chapter I describe the work that was undertaken while building this project. I start by explaining my initial prototyping strategy before giving an overview of the final project structure, how each part of it was implemented and why particular design choices were made. Finally I give a short description of the extensions that were completed and an overview of the repository layout.

\section{Bash prototype}

At first it was necessary to test whether the operations I wanted to perform were possible at all and whether they were possible to implement in the manner that I hoped. This was made easier by the existence of the git command-line tool. As described earlier, this tool is the standard interface to a git store and also has a working implementation of all of the git plumbing commands. As it is a tool intended to work in a shell environment I felt it was prudent to write bash scripts to implement each of the basic features. Bash was selected as it is the shell which I use on my personal machine and is widely supported.

The features implemented in this prototype were basic email delivery, renaming, and conversion of a Maildir to a git store. These all functioned as intended (albeit with a higher level of manual intervention than exists in the final codebase). Due to the success of the prototype, I knew that what I wanted to implement was possible in the way I intended to do it. Therefore it would be possible to translate into OCaml in a more structured way with the opportunity to implement more features.

\section{Gitmaildir}

In this section I describe the the implementation of the final application which I have named ``Gitmaildir'', a portmanteau of ``Git'' and ``Maildir'', the fusion of which is my entire project.

\subsection{Structural overview} \label{section:structuraloverview}

The project is split into 3 logically distinct sections:
\begin{itemize}
  \item \texttt{gitmaildir}, an OCaml library providing all of the functionality necessary to interact with a gitmaildir.
  \item \texttt{gitmaildir\_cli}, a command-line tool to interact with a gitmaildir. It is written in OCaml and uses the features of the \texttt{gitmaildir} library. It is a demo tool to show what operations can be performed and to provide a correct implementation fo them.
  \item \texttt{gitmaildir\_daemon}, another command-line application. It runs as a daemon, syncronising a standard Maildir with a Gitmaildir to allow applications which already know how too use a Maildir to use a Gitmaildir indirectly.
\end{itemize}

Making sure to follow good sofware engineering practices, I implemented unit tests for all major functionality. This was so that it could be confirmed that methods performed the same operations I expected and planned them to, so that it could be confirmed that methods were still performing the same operation after changes had been made and so that I could be sure that all edge cases worked correctly.

\subsection{Mapping between Maildir and Git store}

As a Maildir is simply files stored in directories and git is designed to store files in different versions, the mapping is mostly straightforward. A Gitmaildir follows exactly the same structure as a Maildir except that it does not have the \texttt{tmp} folder. The reason for this omission is that the \texttt{tmp} folder is used for concurrency protections when writing to the filesystem. However this is all managed by the gitmaildir client in use which makes it unnecessary to ever write to it. It is therefore unecessary to keep this folder.

Originally there were plans to move metadata such as the flags added to the end of file names into the first line of email files so that the filenames in the git store did not change. The benefits of this strategy would have been that no semantically important data would be stored in git tree objects (as all that is stored there are file names which are unique identifiers and do not tell us important details about the data contained within). However, this adds complexity when adding to and reading from a Gitmaildir. It also would mean that changing a flag on an email changes the file hash, and so a new copy of the email is stored under the new hash. Git internally does use forms of diffing to compress the store contents so that this is not as much of an issue. However it does add complexity for no real gain which is why I decided that it was not a worthwhile feature.

An additional feature that Git provides on top of the standard filesystem is branching. This is not used in the basic reperesentation of a Gitmaildir, however it is very useful for the extension features. Therefore it is reserved for these and will be described later in section \ref{section:extensions} 

\subsection{The Gitmaildir Library}

As decided in the requirements analysis, the Gitmaildir library provides the following features:

\begin{itemize}
\item email delivery
\item email move/rename (this includes altering flags)
\item email deletion
\item conversion of a maildir to a gitmaldir (and vice versa)
\item the ability to add different hooks when a modification occurs so that extensions can be implemented more easily
\end{itemize}

All of these operations required interaction between the filesystem and/or interaction with a git store. To manage interaction with a git store I used the library ocaml-git. As all this provided was the means to read and write different types of elements of a git store in a consistent way it was necessary to implement the functionality of some of the git plumbing commands almost from scratch.

The library itself was separated into a few different sections depending on functionality. There is the \texttt{git\_ops} module which implements all the necessary git features on top of ocaml-git. This includes plumbing command features such as adding blobs to git trees and other features such as initialising a Gitmaildir. To implement these I had to follow how git builds commits to leave the store in a correct state. Algorithm \ref{algorithm:addtostore} shows the method used to add a new blob (ie file) to a git store at a particular location in the tree.

\begin{algorithm}[h]
\SetAlgoLined
\DontPrintSemicolon

\KwData{$D=$ data to write to store, $P=$ path as a list}
\KwResult{Store is updated with head pointing to the new tree}

\SetKwFunction{FMain}{AddToTree}
\SetKwProg{Fn}{Function}{:}{}

\BlankLine
\tcc{First we write the data to the store}
$ dataHash \leftarrow \textrm{WriteBlob}(D) $\;

\BlankLine
\tcc{Then we define the function to update the tree}
\SetKwFunction{FMain}{AddToTree}
\SetKwProg{Fn}{Function}{:}{}
\Fn{\FMain{$H$, $L$, $T$}}{
  \eIf{$L = [\,]$}
  {$ tree \leftarrow \textrm{ReadTree}(T) $\;
   $ newTree \leftarrow \textrm{AddElementInTree}(tree, dataHash) $\;
   $ treeHash \leftarrow \textrm{WriteTree}(newTree) $\;
   $ \textbf{return } treeHash $}
  {$ \mathit{head, tail} \leftarrow L $\;
   $ tree \leftarrow \textrm{ReadTree}(T) $\;
   $ subtree \leftarrow \textrm{EntryFromTree}(tree, head) $\;
   \tcc{The recursive call is here}
   $ newSubtreeHash \leftarrow \textrm{AddToTree}(H, tail, subtree) $\;
   $ updatedTree \leftarrow \textrm{ReplaceInTree}(tree, head, newSubtreeHash) $\;
   $ treeHash \leftarrow \textrm{WriteTree}(updatedTree) $\;
   $ \textbf{return } treeHash $\;}
}
\textbf{end}

\BlankLine
\tcc{Now we update the tree and write the new commit}
$ newTreeHash \leftarrow \textrm{AddToTree}(dataHash, P, oldTree) $\;
$ newCommit \leftarrow \textrm{BuildCommit}(newTreeHash, oldCommit) $\;
$ \textrm{UpdateHeadReference}(newCommit) $\;
\caption{How to add data to a Git store}
\label{algorithm:addtostore}
\end{algorithm}
\medskip

In effect this is a standard tree traversal where we walk down to the directory we want to update and then walk back up from that point rewriting all the nodes and pointers along the way. In fact, most operations on the git store involve traversing the tree to a point, making a change of some sort and then walking back up. This is quite useful for implementation as it means that the tree traversal only has to be written once. After writing this I was then able to add quite a few features such as rename, addition and deletion as different modifications. This was fairly straightforward because OCaml is a functional language. This means that it has first class functions so the necessary function can be passed as an argument to the method that implements the tree walking.

While writing these methods it became obvious that a lot of things were harder to read and more verbose than they could be. This was because almost all of the operations interact with the filesystem so they were therefore wrapped in an Lwt monad. Also, these operations can almost all cause errors so they were then wrapped in a Result monad. This made the types quite complicated and so difficult to work with in a way that was both clear and concise. To solve this I added a few helper functions in the form of extra infix operators. These were operators which allowed me to bind or map functions across both or either of the Result and Lwt parts of any value. An example of code written before using these infix operators can be seen in Listing \ref{listing:noinfix}.

\begin{listing}[h]
\begin{minted}{ocaml}
let init_empty_blob store =
  let blob = Store.Value.Blob.of_string "" |> Store.Value.blob in
  Result.map ~f:(Lwt.map (fun h ->
                            Tree.of_list [Tree.entry ".keep" `Normal h]))
                   write_value store blob
  |> Result.map ~f:(Lwt.map Store.Value.tree)
  |> Result.bind ~f:(Lwt.bind write_value store)
  |> Result.bind ~f:(Lwt.bind commit_tree store [] "init")
  |> Result.bind ~f:(Lwt.bind update_ref store Git.Reference.master)
\end{minted}
\caption{Code segment before the use of new infix operators}
\label{listing:noinfix}
\end{listing}

We can see in Listing \ref{listing:noinfix} that there is a lot of repetition in this code. The structures of each line are all almost identical and the nested ordering required means that the operation taking place is not immediately obvious. Therefore, I rewrote the same code using the new infix operators that I had defined.

\begin{listing}[h]
\begin{minted}{ocaml}
let init_empty_blob store =
  let blob = Store.Value.Blob.of_string "" |> Store.Value.blob in
  write_value store blob
  >>|| (fun h -> Tree.of_list [Tree.entry ".keep" `Normal h])
  >>|| Store.Value.tree
  >>== write_value store
  >>== commit_tree store [] "init"
  >>== update_ref store Git.Reference.master
\end{minted}
\caption{Code segment with the use of new infix operators}
\label{listing:infix}
\end{listing}

We can see in Listing \ref{listing:infix} the nested application of two functions is now contained in one infix operator which also fits visually with the flow of the data through the code. Because of these two factors the code became quicker to write and it also felt more natural to read. Although this is just a small example, these patterns exist in almost every function in the codebase, meaning that it does have a large impact on efficiency when both reading and writing code throughout the project.

Once implementation of the necessary git operations was complete it was possible to move on to writing Maildir operations. These are all held in a separate module aptly named \texttt{maildir}. Most of the functionality was created by wrapping sequences of functions from \texttt{git\_ops} to provide standalone Maildir functions without having to worry about the Git backend. In fact this was one of the many uses of an OCaml functor in my project. When one wishes to use the Maildir module they must first pass in a module which provides the necessary Git operations. This implementation is then used by the \texttt{maildir} module to interact with a git store.

The implementation of most operations such as deleting an email was fairly straightforward as they just consist of reading information about the store, performing the modification and then writing back any results\footnote{One extra feature that did need adding to this flow was locking but this is described later in section \ref{section:concurrency}}. However, a few operations required some new thought. One such operation was email delivery as we have to assign a unique name to each new email. The format for this is specified by the original author\cite{bernstein2000maildir} as:
\begin{quote}
  Okay, so you're writing messages. A unique name has three pieces, separated by dots. On the left is the result of time() or the second counter from gettimeofday(). On the right is the result of gethostname(). (To deal with invalid host names, replace / with \textbackslash057 and : with \textbackslash072.) In the middle is a delivery identifier, discussed below.
\end{quote}
This works under most circumstances but it is still possible to end up with two identical names. Therefore we need a solution for collisions. As the original implementation of Maildir uses the filesystem the suggestion is to sleep 2 seconds and try again. Because of using Git the name collision check takes longer and so will take also longer to throw an error. My current implementation throws an error if the name is taken and the process has to try again. I think this is similar behaviour to the original, as in this case the delivering process cannot check for itself if the name collides. However, due to the locking in use (described in more detail in section \ref{section:concurrency}), it would be possible to safely generate the name at the point of adding it to the git tree whilst also not having to worry about collisions. This would be the best solution in terms of speed, but it would violate the layers of abstraction in my modules which is why I chose not to implement it.

For the extensions, it was necessary to have the ability to perform extra operations when every action is taken on a Gitmaildir. I implemented this by wrapping every function in another that would be provided both the correct arguments and a list of extension functions in use. The extension functions are then passed the name of the operation called (in the form of a variant type) and the arguments given. This provides a lot of flexibility while not interfering with the core operations of the Gitmaildir library. This does mean that extensions must be compiled in as part of the library but they were never intended to be a feature that end users could write on the fly so I felt that this was not a problem.

\subsection{Command line interface}

I decided as part of my requirements that is would be useful to have a way to interact with a Gitmaildir through the command-line, providing a way to execute all of the operations implemented. This was not only for human interaction, but also as a tool that other programs could call if not able to use the Gitmaildir library directly. I built this with the help of an OCaml library called cmdliner which ``allows the declarative definition of command line interfaces for OCaml''\cite{code_cmdliner}. This allowed me to design and create the interface without having to worry about parsing arguments into the correct type or even to think about whether all the arguments had been provided and any other errors. The library is used by creating a term which is evaluated and terms can be built from sub-terms. The library provides a way to create terms from arguments and a way to create terms from OCaml functions. These terms can then be coupled together to form the complete program term which cmdliner evaluates as your program. The declarative and compositional manner in which this is done was new to me and was at first confusing but after understanding how it worked it made adding and changing arguments in the command-line very simple and quick. It had the further benefit that for similar arguments you can parametrise a function that build a different term based on the argument given which saves time and code. However this strategy was less readable so I did not use it in the end and created each term separately.


\subsection{Daemon}

The purpose of the daemon, as described above, is to synchronise a normal Maildir with a Gitmaildir. This is to allow programs which only work with a Maildir to use a Gitmaildir as a backend indirectly. As with all of the other code this was implemented in OCaml. Like the command-line interface, the interface for the daemon was also created using cmdliner.

There were a many different ways in which I could have implemented the daemon, the main three being continually polling the filesystem (which would have been inefficient), being notified by Gitmaildir clients (but this does not help for clients which only know about Maildir) and subscribing to filesystem changes in a more sensible way. I opted for option 3 by using a file change monitor called fswatch\cite{code_fswatch}. The benefit of using this tool in particular is that it handles interoperability with most major OSs (macOS, Linux, BSD, Windows), and on all of those OSs it uses notifications from the OS for file changes rather than polling the filesystem. This allowed me to focus on programming the syncing process itself rather than worrying about how to be notified of changes on different systems.

Once we have knowledge of a change having happened we have to work out what needs to be done. I did this by calculating a diff between the files in Git storage and those in Maildir storage on every notification. This diff was performed by a manual implementation of the TODO:choose alg diffing (maybe give code?) algorithm. Additions of new emails are easy to handle as we just need to make a new write. Moves are also easy to track as the only name changes come from editing the flags at the end of a file name, the rest of it always remains the same. The more difficult operation comes from deletion as naively it looks the same as an addition to the alternate store. I solved this by using the Git history: If we look at the previous commit it should be the one before the deletion took place. If the email existed in the previous Git commit then a deletion took place (it is the same for the Maildir and Gitmaildir) so we can safely delete from the relevant store.

\subsection{Concurrency protections} \label{section:concurrency}

Maildir was designed in such a way that people implementing it do not need to worry about locking as long as they follow the correct procedure when writing to a Maildir. This was the main point behind its design, but as explained is also why it is not strongly consistent. Implementing a Maildir in Git has meant that all writes to it have to be as part of a Git commit. This unfortunately means that locking is required. The reason for this stems from the structure of a Git repository on disk and can best be explained by an example of when things go wrong. Here is an example of what could happen if two processes try to deliver an email concurrently (using the process described in algorithm \ref{algorithm:addtostore}):

\begin{enumerate}
\item Processes 1 and 2 start their delivery of emails A and B
\item A and B are both written to the store returning hashes
\item Process 1 is returned a modified tree containing A
\item Process 2 is returned a modified tree containing B
\item Process 1 commits its new tree and moves forward the HEAD
\item Process 2 commits its new tree and moves forward the HEAD
\end{enumerate}

At the end of this sequence of actions we have the HEAD reference pointing to a commit which contains email B but not email A. The previous commit in the history will contain email A and not email B. However, the expected result would be for the HEAD commit to contain A and B and the previous one to contain only one of them (depending on order of delivery). The only way to achieve this is some form of concurrency control. I decided that the simplest solution would be to use locking.

I implemented the locking using a combination of the BSD tool/system call flock\cite{manual_flock} and the Mutex module from the OCaml standard library. Flock was necessary for interprocess locks as multiple processes could be trying to write at the same time and should not be allowed to. Flock is very simple, it creates a lock associated with a particular file (I created a file to act as the lock file for any process called \texttt{.global\_lock}) in the filesystem. This can be shared, exclusive or non-blocking. I decided on exclusive for all cases. It would be possible to use a shared lock for reading but this would have added further complexity. The reason that it was also necessary to use Mutex was that Flock prevents different processes from holding a lock at the same time but is effectively reentrant for the same process. Therefore if we need concurrency protections and are executing inside the same process then something else to provide the locking. The reason that Mutex could not be used for all the locking is the opposite from Flock: it only works inside a single process.

When adding the locking strategy, I initially put a lock around every Maildir operation. This did work and provided safety, however, more granular locking was possible. The only place where a write could collide is in updating the which commit is the HEAD of the repository. Therefore this is the only operation that we need a lock around. However, unlike the whole-operation locking this does not solve the race-condition described above. The way that this can be resolved is by checking if we have had a race inside the lock. If we have not then it is okay to continue. If we have then our tree is missing at least one change so we have to roll back and try again. Due to the possible need to roll back, this could end up being slower than the purely sequential method. I noticed something else about the flow of adding to a store. Adding the blob and getting a hash back is an idempotent operation due to the content-addressable storage. This is one of the longer running parts of the process but will never be part of the race so we also only have to every perform it once. Therefore I was able to remove this stage from the roll back. Comparisons of the different strategies can be seen in section \ref{section:evaluation} of this document.

\subsection{Build system}

For the project I chose to use the Dune\cite{code_dune} build system. This was because it is the most widely used build system for OCaml currently, has a lot of documentation, has all the features I needed and is quick (it supports concurrent builds). The main benefits to using it were that I was able to create build files for each part of the project separately, mentioning their different dependencies and what they were (eg command-line interface or library) and a single file in the root directory to specify it was one project. Given those files Dune can build, install and test the entire project.

\section{Extensions} \label{section:extensions}

TODO: once extensions are complete

\section{Repository overview}

The code repository is laid out in a fairly self-descriptive way. The top level contains build files, the license, a readme giving instructions on how to build and use the tools and library and the all the code separated into subdirectories with the same structure as specified in \ref{section:structuraloverview}. There is also a directory of tests and the code used to record the data used in the evaluation.
